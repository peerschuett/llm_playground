{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summarizing a set of scientific papers\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## To extract info from scientific pdf papers:\n",
    "\n",
    "used https://github.com/UCREL/science_parse_py_api/tree/master/\n",
    "\n",
    "> pip install science_parse_api\n",
    "\n",
    "> docker run -p 127.0.0.1:8080:8080 --rm --init ucrel/ucrel-science-parse:3.0.1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "import json\n",
    "\n",
    "from tqdm import tqdm\n",
    "\n",
    "papers_dir = r\"C:\\Users\\elba_ro\\Documents\\projects\\github\\dissertation\\chapter2_related_work\\subfolder\"\n",
    "\n",
    "#temp_path = Path(papers_dir,  'kiesel2022-identifying-the-human-values-behind-arguments.pdf').resolve()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pprint\n",
    "from science_parse_api.api import parse_pdf\n",
    "from langchain import LLMChain\n",
    "\n",
    "host = 'http://127.0.0.1'\n",
    "port = '8080'\n",
    "#output_dict = parse_pdf(host, temp_path, port=port)\n",
    "\n",
    "#pp = pprint.PrettyPrinter(indent=4)\n",
    "#pp.pprint(output_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def content_only(_dict: dict) -> str :\n",
    "    all_content = \"\"\n",
    "    for section in _dict[\"sections\"]:\n",
    "        \n",
    "        heading_str = f\"{section['heading']}\\n\" if \"heading\" in section.keys()  and len(section['heading'])>0 else \"\"\n",
    "        text_str = f\"{section['text']}\" if \"text\" in section.keys() and len(section['text'])>0  else \"\"\n",
    "        combined = f\"{heading_str}{text_str}\" \n",
    "        \n",
    "        all_content = f\"{all_content}\\n\" if len(all_content) > 0 and len(combined)> 0 else all_content\n",
    "        all_content = f\"{all_content}{combined}\"\n",
    "    return all_content\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#text = content_only(output_dict)\n",
    "#print(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import openai\n",
    "import os\n",
    "\n",
    "from dotenv import load_dotenv, find_dotenv\n",
    "_ = load_dotenv(find_dotenv())\n",
    "\n",
    "openai.api_key  = os.getenv('OPENAI_API_KEY')\n",
    "\n",
    "def get_completion(prompt, model=\"gpt-3.5-turbo\"):\n",
    "    messages = [{\"role\": \"user\", \"content\": prompt}]\n",
    "    response = openai.ChatCompletion.create(\n",
    "        model=model,\n",
    "        messages=messages,\n",
    "        temperature=0, # this is the degree of randomness of the model's output\n",
    "    )\n",
    "    return response.choices[0].message[\"content\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a new OpenAI instance\n",
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain.prompts.chat import (\n",
    "    ChatPromptTemplate,\n",
    "    SystemMessagePromptTemplate,\n",
    "    AIMessagePromptTemplate,\n",
    "    HumanMessagePromptTemplate,\n",
    ")\n",
    "\n",
    "_ChatOpenAI_ = ChatOpenAI(model_name=\"gpt-3.5-turbo\", temperature=0)\n",
    "\n",
    "\n",
    "def create_prompt_template(prompt):\n",
    "    system_message_prompt = SystemMessagePromptTemplate.from_template(prompt)\n",
    "    human_template=\"{scientific_content}\"\n",
    "    human_message_prompt = HumanMessagePromptTemplate.from_template(human_template)\n",
    "    return [system_message_prompt, human_message_prompt]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from glob import glob\n",
    "import json\n",
    "import pandas as pd\n",
    "\n",
    "def summarize_scientific_papers(source_path:str) -> pd.DataFrame:\n",
    "\n",
    "    pdfs: list[str] = glob(f\"{source_path}/*.pdf\")\n",
    "    print(f\"Summarizing papers from the dir {source_path} which contains {len(pdfs)}.\")\n",
    "    \n",
    "    chatgpt_outputs = []\n",
    "    \n",
    "    #The text is delimited with triple backticks.\n",
    "    num = 1\n",
    "    for paper in tqdm(pdfs):\n",
    "        try:\n",
    "            prompt = \"\"\"\n",
    "            Your task is to provide a comprehensive summary of a scientific paper.\n",
    "\n",
    "            The result is intended for academic researchers.\n",
    "\n",
    "            1. Create a short summary for the paper.\n",
    "            2. Define the type of datasets used in the experiments, if any. Otherwise NA.\n",
    "            3. Extract the top 5 topics of this text\n",
    "            4. Infer the top 5 1-3words topics of this text\n",
    "            5. Define in one sentence the main task tackled in this text\n",
    "            6. Does this paper mention argumentation? answer by True or False.\n",
    "\n",
    "            Format your response as a JSON object with \\\n",
    "            \"summary\", \"dataset_type\", \"top_5_topics\", \"top_short_topics\", \"task\" and \"is_argumentative\".\n",
    "\n",
    "            text: \n",
    "            \"\"\"\n",
    "            path = Path(paper).resolve()\n",
    "            output_dict = parse_pdf(host, path, port=port)\n",
    "            text = content_only(output_dict)\n",
    "\n",
    "            #prompt.format(text = text)\n",
    "            #prompt = prompt if len(prompt) <= 4097 else prompt[0:4093]+\"'''\"\n",
    "\n",
    "            lc_prompt = ChatPromptTemplate.from_messages(create_prompt_template(prompt))\n",
    "            llm_chain = LLMChain(llm=_ChatOpenAI_, prompt=lc_prompt)\n",
    "            \n",
    "            _MAX_ = 4097 - len(prompt)\n",
    "            text_truncated = text[0:_MAX_] if len(text) > _MAX_ else text\n",
    "            response = llm_chain.run(scientific_content = text_truncated)# 'get_completion(prompt)\n",
    "            response_dict = json.loads(response)\n",
    "            response_dict.update(output_dict)\n",
    "\n",
    "            chatgpt_outputs.append(response_dict)\n",
    "            num = num+1\n",
    "            if num>3: break\n",
    "\n",
    "        except Exception as e:\n",
    "            print(e)\n",
    "            print(f\"Failed to get a response for the paper: {paper}\")   \n",
    "        \n",
    "    df = pd.DataFrame(chatgpt_outputs)\n",
    "    df.to_csv(f\"{source_path}/chatgpt_summary.csv\")\n",
    "    return df\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Summarizing papers from the dir C:\\Users\\elba_ro\\Documents\\projects\\github\\dissertation\\chapter2_related_work\\subfolder which contains 26.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  8%|â–Š         | 2/26 [00:52<10:30, 26.26s/it]\n"
     ]
    }
   ],
   "source": [
    "df = summarize_scientific_papers(papers_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>summary</th>\n",
       "      <th>dataset_type</th>\n",
       "      <th>top_5_topics</th>\n",
       "      <th>top_short_topics</th>\n",
       "      <th>task</th>\n",
       "      <th>is_argumentative</th>\n",
       "      <th>abstractText</th>\n",
       "      <th>authors</th>\n",
       "      <th>id</th>\n",
       "      <th>references</th>\n",
       "      <th>sections</th>\n",
       "      <th>title</th>\n",
       "      <th>year</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>The paper discusses the challenges in assessin...</td>\n",
       "      <td>NA</td>\n",
       "      <td>[argumentation quality, computational argument...</td>\n",
       "      <td>[argumentation, quality, computational, resear...</td>\n",
       "      <td>Defining a common ground for assessing argumen...</td>\n",
       "      <td>True</td>\n",
       "      <td>Research on computational argumentation faces ...</td>\n",
       "      <td>[{'affiliations': [], 'name': 'Henning Wachsmu...</td>\n",
       "      <td>SP:183a8c7eff441560158c7ebee5cfc11554362b54</td>\n",
       "      <td>[{'authors': ['Richard Correnti', 'Lindsay Cla...</td>\n",
       "      <td>[{'text': 'Proceedings of the 15th Conference ...</td>\n",
       "      <td>Computational Argumentation Quality Assessment...</td>\n",
       "      <td>2017</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>The paper benchmarks the quality dimensions of...</td>\n",
       "      <td>English debate portal arguments on 16 topics s...</td>\n",
       "      <td>[argument quality assessment, computational li...</td>\n",
       "      <td>[argument, quality, text, supervised, NLP]</td>\n",
       "      <td>The main task tackled in this text is to bench...</td>\n",
       "      <td>True</td>\n",
       "      <td>Several quality dimensions of natural language...</td>\n",
       "      <td>[{'affiliations': [], 'name': 'Henning Wachsmu...</td>\n",
       "      <td>SP:393ae96a3463be78f1f1e195a180de093698e119</td>\n",
       "      <td>[{'authors': ['Charu C. Aggarwal', 'ChengXiang...</td>\n",
       "      <td>[{'text': 'Proceedings of the 28th Internation...</td>\n",
       "      <td>Intrinsic Quality Assessment of Arguments</td>\n",
       "      <td>2020</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>The paper discusses the need for adaptive argu...</td>\n",
       "      <td>Student-written persuasive pitches</td>\n",
       "      <td>[Adaptive argumentation support systems, Argum...</td>\n",
       "      <td>[Argumentation support, Mining, Linguistics, P...</td>\n",
       "      <td>The main task tackled in this text is the deve...</td>\n",
       "      <td>True</td>\n",
       "      <td>We introduce an argumentation annotation appro...</td>\n",
       "      <td>[{'affiliations': [], 'name': 'Thiemo Wambsgan...</td>\n",
       "      <td>SP:a37de7234771ca8baf10262bbd764dcd5c82378a</td>\n",
       "      <td>[{'authors': ['Albert Bandura.'], 'title': 'So...</td>\n",
       "      <td>[{'text': 'Proceedings of the 60th Annual Meet...</td>\n",
       "      <td>Modeling Persuasive Discourse to Adaptively Su...</td>\n",
       "      <td>2022</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             summary  \\\n",
       "0  The paper discusses the challenges in assessin...   \n",
       "1  The paper benchmarks the quality dimensions of...   \n",
       "2  The paper discusses the need for adaptive argu...   \n",
       "\n",
       "                                        dataset_type  \\\n",
       "0                                                 NA   \n",
       "1  English debate portal arguments on 16 topics s...   \n",
       "2                 Student-written persuasive pitches   \n",
       "\n",
       "                                        top_5_topics  \\\n",
       "0  [argumentation quality, computational argument...   \n",
       "1  [argument quality assessment, computational li...   \n",
       "2  [Adaptive argumentation support systems, Argum...   \n",
       "\n",
       "                                    top_short_topics  \\\n",
       "0  [argumentation, quality, computational, resear...   \n",
       "1         [argument, quality, text, supervised, NLP]   \n",
       "2  [Argumentation support, Mining, Linguistics, P...   \n",
       "\n",
       "                                                task  is_argumentative  \\\n",
       "0  Defining a common ground for assessing argumen...              True   \n",
       "1  The main task tackled in this text is to bench...              True   \n",
       "2  The main task tackled in this text is the deve...              True   \n",
       "\n",
       "                                        abstractText  \\\n",
       "0  Research on computational argumentation faces ...   \n",
       "1  Several quality dimensions of natural language...   \n",
       "2  We introduce an argumentation annotation appro...   \n",
       "\n",
       "                                             authors  \\\n",
       "0  [{'affiliations': [], 'name': 'Henning Wachsmu...   \n",
       "1  [{'affiliations': [], 'name': 'Henning Wachsmu...   \n",
       "2  [{'affiliations': [], 'name': 'Thiemo Wambsgan...   \n",
       "\n",
       "                                            id  \\\n",
       "0  SP:183a8c7eff441560158c7ebee5cfc11554362b54   \n",
       "1  SP:393ae96a3463be78f1f1e195a180de093698e119   \n",
       "2  SP:a37de7234771ca8baf10262bbd764dcd5c82378a   \n",
       "\n",
       "                                          references  \\\n",
       "0  [{'authors': ['Richard Correnti', 'Lindsay Cla...   \n",
       "1  [{'authors': ['Charu C. Aggarwal', 'ChengXiang...   \n",
       "2  [{'authors': ['Albert Bandura.'], 'title': 'So...   \n",
       "\n",
       "                                            sections  \\\n",
       "0  [{'text': 'Proceedings of the 15th Conference ...   \n",
       "1  [{'text': 'Proceedings of the 28th Internation...   \n",
       "2  [{'text': 'Proceedings of the 60th Annual Meet...   \n",
       "\n",
       "                                               title  year  \n",
       "0  Computational Argumentation Quality Assessment...  2017  \n",
       "1          Intrinsic Quality Assessment of Arguments  2020  \n",
       "2  Modeling Persuasive Discourse to Adaptively Su...  2022  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from IPython.display import display, HTML\n",
    "\n",
    "display(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>summary</th>\n",
       "      <th>dataset_type</th>\n",
       "      <th>top_5_topics</th>\n",
       "      <th>top_short_topics</th>\n",
       "      <th>task</th>\n",
       "      <th>is_argumentative</th>\n",
       "      <th>abstractText</th>\n",
       "      <th>authors</th>\n",
       "      <th>id</th>\n",
       "      <th>references</th>\n",
       "      <th>sections</th>\n",
       "      <th>title</th>\n",
       "      <th>year</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>The paper discusses the importance of assessin...</td>\n",
       "      <td>NA</td>\n",
       "      <td>[Assessing argumentation quality, Computationa...</td>\n",
       "      <td>[Argumentation quality, Computational approach...</td>\n",
       "      <td>Defining a common ground for assessing argumen...</td>\n",
       "      <td>True</td>\n",
       "      <td>Research on computational argumentation faces ...</td>\n",
       "      <td>[{'affiliations': [], 'name': 'Henning Wachsmu...</td>\n",
       "      <td>SP:06a08af6efb871cd8a94b483e071914e9c859046</td>\n",
       "      <td>[{'authors': ['Richard Correnti', 'Lindsay Cla...</td>\n",
       "      <td>[{'text': 'Proceedings of the 15th Conference ...</td>\n",
       "      <td>Computational Argumentation Quality Assessment...</td>\n",
       "      <td>2017</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             summary dataset_type  \\\n",
       "0  The paper discusses the importance of assessin...           NA   \n",
       "\n",
       "                                        top_5_topics  \\\n",
       "0  [Assessing argumentation quality, Computationa...   \n",
       "\n",
       "                                    top_short_topics  \\\n",
       "0  [Argumentation quality, Computational approach...   \n",
       "\n",
       "                                                task  is_argumentative  \\\n",
       "0  Defining a common ground for assessing argumen...              True   \n",
       "\n",
       "                                        abstractText  \\\n",
       "0  Research on computational argumentation faces ...   \n",
       "\n",
       "                                             authors  \\\n",
       "0  [{'affiliations': [], 'name': 'Henning Wachsmu...   \n",
       "\n",
       "                                            id  \\\n",
       "0  SP:06a08af6efb871cd8a94b483e071914e9c859046   \n",
       "\n",
       "                                          references  \\\n",
       "0  [{'authors': ['Richard Correnti', 'Lindsay Cla...   \n",
       "\n",
       "                                            sections  \\\n",
       "0  [{'text': 'Proceedings of the 15th Conference ...   \n",
       "\n",
       "                                               title  year  \n",
       "0  Computational Argumentation Quality Assessment...  2017  "
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from IPython.core.interactiveshell import InteractiveShell\n",
    "InteractiveShell.ast_node_interactivity = \"all\"\n",
    "df\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
